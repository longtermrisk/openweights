max_steps = 5
seq_len = 256
inference_gpu_ids = [0]
trainer_gpu_ids = [1]
output_dir = "outputs/toy_rl"

[model]
name = "Qwen/Qwen3-0.6B"

[orchestrator]
batch_size = 8
rollouts_per_example = 2

[orchestrator.sampling]
max_tokens = 32

[[orchestrator.env]]
id = "toy-env"

[trainer]

[inference]
